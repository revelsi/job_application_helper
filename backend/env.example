# Job Application Helper v1.0.0 - Configuration

# =============================================================================
# LLM API Configuration
# =============================================================================

# OpenAI API Key (Primary LLM - GPT-4.1-mini for optimal performance)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (Primary LLM - Claude 3.5 Sonnet for document analysis)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Default LLM Provider (openai only)
# Recommended: openai (GPT-4.1-mini) for optimal performance and cost efficiency
DEFAULT_LLM_PROVIDER=openai

# =============================================================================
# Application Settings
# =============================================================================

# Environment (production, development)
ENVIRONMENT=production

# Application Port
PORT=8000

# Log Level (INFO, WARNING, ERROR, DEBUG)
LOG_LEVEL=INFO

# =============================================================================
# Data Storage Configuration
# =============================================================================

# Local data directory path
DATA_DIR=./data



# Documents storage path
DOCUMENTS_PATH=./data/documents

# Cache directory path
CACHE_PATH=./data/cache

# =============================================================================
# Security Settings
# =============================================================================

# Enable/disable encryption for sensitive data (true/false)
# Default: true (encryption enabled for security)
ENABLE_ENCRYPTION=true

# Encryption key for sensitive data (auto-generated on first run if not provided)
# To generate manually: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
ENCRYPTION_KEY=your_encryption_key_here

# Maximum file upload size (in MB)
MAX_UPLOAD_SIZE_MB=10

# =============================================================================
# Document Processing Configuration
# =============================================================================

# Maximum context length for LLM (total across all documents)
# GPT-4.1-mini supports 128K tokens (~500K characters), so we can be generous
# Default: 100,000 characters (~25K tokens) leaves plenty of room for responses
MAX_CONTEXT_LENGTH=100000

# Per-document context limits (characters)
# These control how much content is included from each document type
# With GPT-4.1-mini's large context window, we can include full documents

# Maximum content from candidate documents (CV, cover letters, certificates, etc.)
# Default allows for very detailed CVs and multiple documents
MAX_CANDIDATE_DOC_LENGTH=50000

# Maximum content from job description documents
# Default allows for comprehensive job postings with detailed requirements
MAX_JOB_DOC_LENGTH=30000

# Maximum content from company information documents  
# Default allows for detailed company profiles, values, and culture info
MAX_COMPANY_DOC_LENGTH=20000

# Maximum tokens for chat responses (increase for longer responses like cover letters)
# Default: 4000 tokens allows for detailed cover letters and comprehensive responses
# Note: GPT-4.1-mini supports up to 16K output tokens
CHAT_MAX_TOKENS=4000

# =============================================================================
# Company Information Retrieval (OPTIONAL)
# =============================================================================

# LinkedIn API (OPTIONAL - for future LinkedIn integration)
LINKEDIN_API_KEY=your_linkedin_api_key_here

# Rate limiting (requests per minute)
API_RATE_LIMIT=60 

# Python version: 3.9+ required 