# Job Application Helper v1.0.0 - Configuration

# =============================================================================
# LLM API Configuration
# =============================================================================

# OpenAI API Key (Primary LLM - GPT-5-mini for optimal performance)
OPENAI_API_KEY=your_openai_api_key_here

# Mistral AI API Key (Reasoning LLM - Magistral Small for step-by-step reasoning)
MISTRAL_API_KEY=your_mistral_api_key_here

# Hugging Face API Key (Open-source models - gpt-oss-20B and others)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Ollama Configuration (Local LLM - no API key required)
# Base URL for Ollama service (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
# Timeout for Ollama requests (seconds)
OLLAMA_TIMEOUT=60

# Default LLM Provider (optional - auto-selects based on availability)
# Options: openai, mistral, huggingface, ollama
DEFAULT_LLM_PROVIDER=

# Provider Selection:
# - If API keys are set above, those providers will be automatically available
# - If no keys are set, configure providers through the web UI
# - Only one provider can be active at a time

# =============================================================================
# Application Settings
# =============================================================================

# Environment (production, development)
ENVIRONMENT=production

# Application Port
PORT=8000

# Log Level (INFO, WARNING, ERROR, DEBUG)
LOG_LEVEL=INFO

# =============================================================================
# Data Storage Configuration
# =============================================================================

# Local data directory path
DATA_DIR=./data

# Documents storage path
DOCUMENTS_PATH=./data/documents

# Cache directory path
CACHE_PATH=./data/cache

# =============================================================================
# Security Settings
# =============================================================================

# Enable/disable encryption for sensitive data (true/false)
# Default: true (encryption enabled for security)
ENABLE_ENCRYPTION=true

# Encryption key for sensitive data (auto-generated on first run if not provided)
# To generate manually: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
ENCRYPTION_KEY=your_encryption_key_here

# Maximum file upload size (in MB)
MAX_UPLOAD_SIZE_MB=10

# =============================================================================
# Document Processing Configuration
# =============================================================================

# Maximum context length for LLM (total across all documents)
# GPT-5-mini supports 128K tokens (~500K characters), so we can be generous
# Default: 100,000 characters (~25K tokens) leaves plenty of room for responses
MAX_CONTEXT_LENGTH=100000

# Per-document context limits (characters)
# These control how much content is included from each document type
# With GPT-5-mini's large context window, we can include full documents

# Maximum content from candidate documents (CV, cover letters, certificates, etc.)
# Default allows for very detailed CVs and multiple documents
MAX_CANDIDATE_DOC_LENGTH=50000

# Maximum content from job description documents
# Default allows for comprehensive job postings with detailed requirements
MAX_JOB_DOC_LENGTH=30000

# Maximum content from company information documents  
# Default allows for detailed company profiles, values, and culture info
MAX_COMPANY_DOC_LENGTH=20000

# Maximum tokens for chat responses (increase for longer responses like cover letters)
# Default: 16000 tokens allows for detailed reasoning and comprehensive responses
# Note: GPT-5-mini supports up to 32K output tokens, reasoning models need extra space
CHAT_MAX_TOKENS=16000

# =============================================================================
# Company Information Retrieval (OPTIONAL)
# =============================================================================

# LinkedIn API (OPTIONAL - for future LinkedIn integration)
LINKEDIN_API_KEY=your_linkedin_api_key_here

# Rate limiting (requests per minute)
API_RATE_LIMIT=60

# Python version: 3.9+ required 